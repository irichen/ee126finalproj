{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(filename, paperlimit):\n",
    "    if (os.path.exists(filename+\".p\")):\n",
    "        json_data = pickle.load( open( filename+\".p\", \"rb\" ) )\n",
    "    else:\n",
    "        data = \"[\"\n",
    "        with open(filename+\".txt\") as myfile:\n",
    "            counter = 0 \n",
    "            for line in myfile:\n",
    "                counter += 1\n",
    "                data += line + \",\"\n",
    "                if counter > paperlimit:\n",
    "                    break\n",
    "\n",
    "        data = data[:-1] + \"]\"\n",
    "\n",
    "        json_data = json.loads(data)\n",
    "        pickle.dump( json_data, open( filename+\".p\", \"wb\" ) )\n",
    "\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded aminer_papers_4 as json\n"
     ]
    }
   ],
   "source": [
    "filename = \"aminer_papers_4\"\n",
    "json_data = loadData(filename, 30000)\n",
    "print(\"Loaded\", filename, \"as json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# papers:  25650\n"
     ]
    }
   ],
   "source": [
    "paper_to_authors = dict()\n",
    "paper_to_journal = dict()\n",
    "\n",
    "for paper_obj in json_data:\n",
    "    if 'id' in paper_obj and 'authors' in paper_obj and 'venue' in paper_obj:\n",
    "        paper = paper_obj['id']\n",
    "        authors = paper_obj['authors']\n",
    "        journal = paper_obj['venue']\n",
    "        \n",
    "        paper_to_authors[paper] = [author['name'] for author in authors]\n",
    "        paper_to_journal[paper] = journal\n",
    "        \n",
    "print(\"# papers: \", len(paper_to_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_to_author_and_papers = dict()\n",
    "\n",
    "for paper_obj in json_data:\n",
    "    if 'references' in paper_obj and 'authors' in paper_obj and 'venue' in paper_obj:\n",
    "        paper_refs = paper_obj['references']\n",
    "        author_and_papers = dict()\n",
    "        for paper_ref in paper_refs:\n",
    "            if paper_ref in paper_to_authors:\n",
    "                authors = paper_to_authors[paper_ref]\n",
    "                for author in authors:\n",
    "                    if author not in author_and_papers:\n",
    "                        author_and_papers[author] = [paper_ref]\n",
    "                    else:\n",
    "                        author_and_papers[author].append(paper_ref)\n",
    "        for author in paper_obj['authors']:\n",
    "            author_to_author_and_papers[author['name']] = author_and_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# authors:  17869\n"
     ]
    }
   ],
   "source": [
    "cleaned_author_to_etc = dict()\n",
    "\n",
    "for obj in author_to_author_and_papers.keys():\n",
    "    if author_to_author_and_papers[obj]:\n",
    "        cleaned_author_to_etc[obj] = author_to_author_and_papers[obj]\n",
    "        \n",
    "print(\"# authors: \", len(author_to_author_and_papers))\n",
    "        \n",
    "value = 5\n",
    "paper_to_if = {key:value for key in paper_to_journal.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nature 880\n",
      "The Lancet 572\n",
      "British Medical Journal 548\n",
      "science 295\n",
      "Science (New York, N.Y.) 166\n",
      "Psyccritiques 163\n",
      "Scientific American 143\n",
      "American Journal of The Medical Sciences 115\n",
      "Lancet (London, England) 102\n",
      "Phytochemistry 102\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(list(paper_to_journal.values()), return_counts = True)\n",
    "journal_occurences = dict(zip(unique, counts))\n",
    "top10_journal_occ = sorted(journal_occurences, key=journal_occurences.get, reverse=True)[:10]\n",
    "for j in top10_journal_occ:\n",
    "    print(j, journal_occurences[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns id of author chosen uniformly randomly\n",
    "def randStartPoint(author_to_score):\n",
    "    idx = np.random.randint(len(author_to_score))\n",
    "    return list(author_to_score.keys())[idx]   #perhaps sorting issues here? check later\n",
    "\n",
    "def getScore(cur_author, proposed_author, author_to_score):\n",
    "    papers = author_to_author_and_papers[cur_author][proposed_author]\n",
    "    score = 0\n",
    "    for paper in papers:\n",
    "        paper_authors = paper_to_authors[paper]\n",
    "        avg_author_score = np.mean([author_to_score[auth] for auth in paper_authors if auth in author_to_score])\n",
    "        score += avg_author_score * paper_to_if[paper]\n",
    "    \n",
    "    return np.log10(score)\n",
    "\n",
    "def addToExplored(authors_explored, cur_author):\n",
    "    if cur_author in authors_explored.keys():\n",
    "        authors_explored[cur_author] += 1\n",
    "    else:\n",
    "        authors_explored[cur_author] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphtraversal(num_trials, num_walks_per_trial):\n",
    "#     outputs = []\n",
    "#     list_of_author_to_score = []\n",
    "    numAuthors = len(author_to_author_and_papers)\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        authors_explored = {}\n",
    "        deadend = 0\n",
    "        p_accept_lt_1 = 0\n",
    "        trial_output = np.zeros((numAuthors, num_walks_per_trial))\n",
    "        \n",
    "        startScore = 1\n",
    "        author_to_score = collections.OrderedDict([(author, startScore) for author in author_to_author_and_papers.keys()])\n",
    "        \n",
    "        print(\"\\n Trial number \", str(i+1), \"/\", num_trials)\n",
    "    \n",
    "        # Select uniform start point\n",
    "        cur_author = randStartPoint(author_to_score)\n",
    "        addToExplored(authors_explored, cur_author)\n",
    "        \n",
    "        for num_walk in range(num_walks_per_trial):\n",
    "            if len(author_to_author_and_papers[cur_author]) == 0: #current author is a dead end\n",
    "                cur_author = randStartPoint(author_to_score)\n",
    "                addToExplored(authors_explored, cur_author)\n",
    "                deadend += 1\n",
    "            else:\n",
    "                tries = 10\n",
    "                for t in range(tries):\n",
    "                    idx = np.random.randint(len(author_to_author_and_papers[cur_author]))\n",
    "                    proposed_author = list(author_to_author_and_papers[cur_author].keys())[idx]\n",
    "                    if proposed_author in author_to_score:\n",
    "                        break\n",
    "                if proposed_author not in author_to_score:\n",
    "                    cur_author = randStartPoint(author_to_score)\n",
    "                    addToExplored(authors_explored, cur_author)\n",
    "                    continue\n",
    "\n",
    "                # Accept with probability p_accept, according to Metropolis Hastings\n",
    "                pi_y = author_to_score[proposed_author]  #pi(x) = score(x)\n",
    "                pi_x = author_to_score[cur_author]\n",
    "                \n",
    "                # Proposal function f(x) = 1/d where d is degree of node x (number of outgoing edges)\n",
    "                f_y = 1 / max(1, len(author_to_author_and_papers[proposed_author]))\n",
    "                f_x = 1 / max(1, len(author_to_author_and_papers[cur_author]))\n",
    "                \n",
    "                p_accept = min(1, (pi_y * f_y) / (pi_x * f_x))\n",
    "                if p_accept < 1:\n",
    "                    p_accept_lt_1 += 1\n",
    "\n",
    "                if proposed_author in author_to_score and np.random.random() < p_accept and proposed_author != cur_author:\n",
    "                    #if accept, update proposed_author's score.  Then move to proposed_author\n",
    "                    author_to_score[proposed_author] += getScore(cur_author, proposed_author, author_to_score)\n",
    "                    cur_author = proposed_author\n",
    "                    addToExplored(authors_explored, cur_author)\n",
    "                    \n",
    "                else:  #if not accept, randomly start again\n",
    "                    cur_author = randStartPoint(author_to_score)\n",
    "                    addToExplored(authors_explored, cur_author)\n",
    "            trial_output[:, num_walk] = list(author_to_score.values())\n",
    "        \n",
    "        # Add trial results to output matrix\n",
    "#         outputs.append(trial_output)\n",
    "#         list_of_author_to_score.append(author_to_score)\n",
    "        print(\"# authors explored: \", len(authors_explored), \" | # total authors: \", len(author_to_score))\n",
    "        print(\"# of deadends: \", deadend, \" | # of p_accept < 1: \", p_accept_lt_1)\n",
    "        \n",
    "        # Plot and display results\n",
    "        top_x = 10\n",
    "        top_authors = sorted(author_to_score, key=author_to_score.get, reverse=True)[:top_x]\n",
    "        top_authors_idx = [list(author_to_score.keys()).index(author) for author in top_authors]\n",
    "        for rank in range(top_x):\n",
    "            print(\"Rank\", rank+1, \":\", top_authors[rank],\n",
    "                  \"| # of visits: \", authors_explored[top_authors[rank]])\n",
    "\n",
    "        plt.figure(figsize=(14,7))\n",
    "        rows, cols = trial_output.shape\n",
    "        for row in top_authors_idx:\n",
    "            y_data = trial_output[row]\n",
    "            plt.plot(range(cols), y_data, '.', label=list(author_to_score.keys())[row])\n",
    "        plt.xlabel(\"walk step\")\n",
    "        plt.ylabel(\"author score\")\n",
    "        plt.title(\"Evolution of author score through MCMC random walk\")\n",
    "        plt.legend()\n",
    "        plt.savefig(filename+\"_trial\"+str(i+1)+\".png\")\n",
    "     \n",
    "#     return outputs, list_of_author_to_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# outputs, list_of_author_to_score = graphtraversal(5, 30000)\n",
    "graphtraversal(5, 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
